{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuErVRvSQf4F"
      },
      "source": [
        "# Lab2 - AI - Convolutional Neural networks for image recognition\n",
        "\n",
        "**R4.A.13 - BUT2 - IUT Vannes**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "UsvsNDplQf4G"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMX6fHloQf4H"
      },
      "source": [
        "In this lab, we will first build and train a convolutional neural network (CNN) for digit recognition from the MNIST dataset. Results will be compared with those obtained by neural networks in Lab1.\n",
        "\n",
        "In the second part, we build and train CNNs for color object detection from the CIFAR10 dataset.\n",
        "\n",
        "This lab was prepared based on the tutorials: (https://datahacker.rs/005-pytorch-convolutional-neural-network-on-mnist-in-pytorch/) and (https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        "\n",
        "Please note that the implementations from these tutorials need to be adapted and corrected. A simple copy/paste will not work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxOOiyrUGFBv"
      },
      "source": [
        "**Setting up the environment**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH7cvRHzGJG6"
      },
      "source": [
        "# Import required packages from Pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "\n",
        "# moves your model to train on your gpu if available else it uses your cpu\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is your GPU ?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "yZlQXmLdfy6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 1: CNNs for digit recognition from MNIST dataset"
      ],
      "metadata": {
        "id": "snj0tTsPQ_5p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVJ9WMDkI2f4"
      },
      "source": [
        "### **1. Loading MNIST dataset from torchvision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2V6e-0mzQf4J"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transform to normalize data\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.1307,),(0.3081,))\n",
        "                                ])\n",
        "\n",
        "# Download and load the training data and the validation (test) data\n",
        "train_set = datasets.MNIST('DATA_MNIST/', download=True, train=True, transform=transform)\n",
        "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "\n",
        "validation_set = datasets.MNIST('DATA_MNIST/', download=True, train=False, transform=transform)\n",
        "validationLoader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the training size, test size, number of class\n",
        "print(\"Train size : \", len(train_set))\n",
        "print(\"validation size : \", len(validation_set))"
      ],
      "metadata": {
        "id": "qdGFhKyhixky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the size of the image tensors and label tensors\n",
        "training_data = enumerate(trainLoader)\n",
        "batch_idx, (images, labels) = next(training_data)\n",
        "\n",
        "print(images.shape) # the size of the image\n",
        "print(labels.shape) # the size of the labels"
      ],
      "metadata": {
        "id": "LMp9RgUULgQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLJLu3XIQf4Q",
        "scrolled": true
      },
      "source": [
        "# Display some image samples using matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(0,12):\n",
        "    plt.subplot(3, 4, i+1)\n",
        "    plt.imshow(images[i].numpy().squeeze(), cmap='gray'); plt.axis('off')\n",
        "    plt.title(\"label: \" + str(labels[i].numpy().squeeze()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0m7Fp6dQf4U"
      },
      "source": [
        "### **2. Build a convolutional neural network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vcyFKh7Qf4b"
      },
      "source": [
        "Let's define a **convolutional neural network** with 2 conv layers and 1 fc layer\n",
        "- first conv layer: 32 filters of size $5\\times 5$, stride 1, padding 2\n",
        "- maxpooling layer: size 2\n",
        "- second conv layer: 64 filters of size $5\\times 5$, stride 1, padding 2\n",
        "- maxpooling layer: size 2\n",
        "- fully-connected layer with 128 neurons\n",
        "- activation ReLu (after each conv layer and the fc layer)\n",
        "- do not use *dropout* layer (as proposed in the tutorial) for the moment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "# to complete"
      ],
      "metadata": {
        "id": "bzmkNtd6iHME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now initialize the network"
      ],
      "metadata": {
        "id": "4G_ZUTc9krgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "gSbMPD3fObtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---------------Question 1---------------**\n",
        "\n",
        "*   Cacluate the output size of feature maps after each layer of the network.\n",
        "*   Calculate also the total number of parameters of the network\n",
        "*   Print the total number of trainable parameters in Pytorch ?"
      ],
      "metadata": {
        "id": "B7IW51Loj-wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print number of total trainable parameters\n",
        "# to complete\n"
      ],
      "metadata": {
        "id": "gIQqFLzpmPqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3LVhOAdQf4d"
      },
      "source": [
        "### **3. Train the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set up the optimizer and the loss function. You can use the Stochastic Gradient Descent optimizer (SGD) and the Cross-entropy loss as proposed by the tutorial."
      ],
      "metadata": {
        "id": "aSawxt7YcT8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer =\n",
        "# criterion ="
      ],
      "metadata": {
        "id": "pnxp9T-OnPBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train and evaluate/validate the model (during the training)"
      ],
      "metadata": {
        "id": "l9o5T6tmc7j5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzgvonoZQf4d"
      },
      "source": [
        "# to complete\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s plot our loss and accuracies and see if they are falling or growing.\n",
        "\n"
      ],
      "metadata": {
        "id": "AKSTHe0SdKFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss curves\n",
        "\n"
      ],
      "metadata": {
        "id": "KbhjckryPT4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the accuracy curves\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3DE3sL1PWl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---------------Question 2---------------**\n",
        "\n",
        "*  Your remarks and comments about the training process compared to the neural networks in Lab1 ?\n",
        "*  How could we improve the performance ?"
      ],
      "metadata": {
        "id": "V5XNtf1YemNl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxaNP07gQf4i"
      },
      "source": [
        "### **4. Evaluation a trained network**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once our model is trained, we can simply use the trained weights to make some new predictions by turning off the gradients.\n",
        "\n",
        "Let's first predict label for a single image."
      ],
      "metadata": {
        "id": "CtEcHaiLfA7H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCK4iTOfQf4j"
      },
      "source": [
        "# to complete\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict labels for a batch"
      ],
      "metadata": {
        "id": "WhDR_0EzfIsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to complete\n"
      ],
      "metadata": {
        "id": "U7hW6patUGAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geMMfsGGUHun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the performance on the whole validation set"
      ],
      "metadata": {
        "id": "OP1hE_klf5ID"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Dhsx2IQf4l"
      },
      "source": [
        "# to complete\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRWjiSaQQf4t"
      },
      "source": [
        "### **5. Building other CNNs**\n",
        "You can also create and test other CNNs by changing the number of filters, adding more layers, etc.\n",
        "\n",
        "Report the performance and comments on your work\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "J2z71IIFQf4u"
      },
      "source": [
        "# your work\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XhoC1PF9Qf4x"
      },
      "source": [
        "# your work\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hE79JZTgQf4y"
      },
      "source": [
        "# your work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 2: CNNs for color object recognition from CIFAR10 dataset\n",
        "\n",
        "Now let's build CNN models to work on the CIFAR10 dataset.\n",
        "\n",
        "Try to reach the best performance on validation by designing other CNNs."
      ],
      "metadata": {
        "id": "2h4aaIDYRKdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transform to normalize data\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download and load the training data and the validation (test) data\n",
        "train_set = datasets.CIFAR10('DATA_CIFAR/', download=True, train=True, transform=transform)\n",
        "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "\n",
        "validation_set = datasets.CIFAR10('DATA_CIFAR/', download=True, train=False, transform=transform)\n",
        "validationLoader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "3UybBwbZRtMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the training size, test size, number of class\n",
        "print(\"Train size : \", len(train_set))\n",
        "print(\"validation size : \", len(validation_set))"
      ],
      "metadata": {
        "id": "cHimJm7oSl--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the size of the image tensors and label tensors\n",
        "training_data = enumerate(trainLoader)\n",
        "batch_idx, (images, labels) = next(training_data)\n",
        "\n",
        "print(images.shape) # the size of the image\n",
        "print(labels.shape) # the size of the labels"
      ],
      "metadata": {
        "id": "8HYarKvLSoCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some image samples using matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(0,12):\n",
        "    plt.subplot(3, 4, i+1)\n",
        "    plt.imshow((images[i]/ 2 + 0.5).permute(1,2,0).numpy()); plt.axis('off') # (img/2+0.5) is just to unnormalize the image\n",
        "    plt.title(\"label: \" + str(labels[i].numpy().squeeze()))"
      ],
      "metadata": {
        "id": "rbTSjdJ_SrFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to complete\n"
      ],
      "metadata": {
        "id": "NiVf2bwqTsGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to complete\n"
      ],
      "metadata": {
        "id": "7UtjlAvZUO2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to complete\n"
      ],
      "metadata": {
        "id": "RlqaP7_FUWpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to complete\n"
      ],
      "metadata": {
        "id": "pXb3v8o4UZ-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss curves\n"
      ],
      "metadata": {
        "id": "2LvMM2euUdVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the accuracy curves\n"
      ],
      "metadata": {
        "id": "KT5wqbadUu-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---------------Question 3---------------**\n",
        "\n",
        "*  Your remarks and comments about the training process and the performance of CNN on Cifar10 ?\n",
        "*  How could we improve the performance ?"
      ],
      "metadata": {
        "id": "w7PmAK9GRMat"
      }
    }
  ]
}