{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red; text-align:center\">R3.A.15 Machine Learning TP1</h1>\n",
    "\n",
    "### Basol Nathan - Stephan Mathieu - Maccrez Allan - Lederrey Lussandre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Vocabulaire </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"><h3>Différence entre classification et régression</h3></div>\n",
    "\n",
    "- La classification consiste catégoriser des données à partir d'un ensemble de variables quantitatives ou qualitatives.\n",
    "exemple : prédire si un mail est un spam ou non à partir de son contenu.\n",
    "\n",
    "- La régression consiste à prédire une variable quantitative à partir d'un ensemble de variables quantitatives ou qualitatives.\n",
    "exemple : prédire le prix d'une maison à partir de sa surface ou son nombre de pièces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:blue\"><h3>Différence entre apprentissage supervisé et non supervisé</h3></div>\n",
    "\n",
    "- Dans l'apprentissage supervisé, l'algorithme est \"enseigné\" à partir d'exemples étiquetés. On lui donne des données d'entrée avec des étiquettes (par exemple des images de chats avec l'étiquette \"chat\" ou \"chien\").\n",
    "L'objectif de l'algorithme est d'apprendre à faire des prédictions en se basant sur ces étiquettes, afin de pouvoir attribuer correctement des étiquettes aux nouvelles données qu'il n'a jamais vues auparavant.\n",
    "\n",
    "- Dans l'apprentissage non supervisé, l'algorithme n'a pas d'étiquettes à suivre. On lui donne simplement des données d'entrée sans étiquettes. L'objectif de l'algorithme est de découvrir des structures ou des motifs cachés dans les données, généralement en regroupant les données similaires ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nous allons aujourd'hui utiliser le site Scikit-learn.org pour commencer à apprendre les notions de machine learning en utilisant python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Exemple numéro 1 du site scikit-learn.org </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ce code est un exemple d'utilisation de la bibliothèque scikit-learn  pour entraîner un modèle de classification et effectuer des prédictions sur de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0) # randome_state fixe garantit que les résultats seront reproductibles\n",
    "X = [[ 1,  2,  3],  # liste de deux échantillons de donnés\n",
    "    [11, 12, 13]]\n",
    "y = [0, 1]  # les étiquettes associés à chaques échantillons\n",
    "clf.fit(X, y) # apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4, 5, 6], [14, 15, 16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette ligne de code effectue des prédictions sur de nouvelles données. deux nouvelles données sont fournies. Le modèle de forêt aléatoire prédit les classes pour ces nouveaux échantillons. Les prédictions sont [0, 1], ce qui signifie que le modèle a prédit que le premier échantillon appartient à la classe 0 et que le deuxième échantillon appartient à la classe 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[11, 18, 21], [14, 15, 16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a mis des valeurs un peu plus grandes que celles d'avant pour le premier tableau et on voit que ça renvoie 1 pour le premier tableau et 1 pour le deuxième tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Normalisation des données </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    "    )\n",
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "# we can now use it like any other estimator\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " On utilise la bibliothèque scikit-learn (sklearn) pour créer un pipeline d'apprentissage automatique, entraîner un modèle de régression logistique et évaluer sa précision en utilisant l'ensemble de données Iris. <br>\n",
    "\n",
    " Le code crée un pipeline en utilisant make_pipeline. Le pipeline comprend deux étapes : <br>\n",
    "\n",
    "StandardScaler() : Il effectue une mise à l'échelle standard des caractéristiques, ce qui est souvent important pour les modèles de régression logistique. <br>\n",
    "\n",
    "LogisticRegression() : Il s'agit du modèle de régression logistique qui sera utilisé pour la classification.\n",
    "Le pipeline est ensuite entraîné en utilisant les données d'entraînement. <br>\n",
    "\n",
    "Chargement des données Iris :\n",
    "Il utilise load_iris(return_X_y=True) pour charger l'ensemble de données Iris. Les données sont divisées en X (caractéristiques) et y (étiquettes de classe). <br>\n",
    "\n",
    "Division des données :\n",
    "\n",
    "Les données sont ensuite divisées en ensembles d'entraînement (X_train, y_train) et de test (X_test, y_test) en utilisant train_test_split. Cela permet d'évaluer la performance du modèle sur des données qu'il n'a pas vues lors de l'entraînement. <br>\n",
    "\n",
    "Entraînement du modèle :\n",
    "\n",
    "Le pipeline complet (pipe) est ajusté aux données d'entraînement en utilisant pipe.fit(X_train, y_train). <br>\n",
    "\n",
    "Évaluation de la précision :\n",
    "\n",
    "Enfin, la précision du modèle est calculée en utilisant accuracy_score(pipe.predict(X_test), y_test). Le modèle fait des prédictions sur l'ensemble de test (X_test), puis la fonction accuracy_score compare ces prédictions aux vraies étiquettes (y_test) pour calculer la précision du modèle. <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mise en situation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Voici le code du site scikit. Nous allons essayer de le comprendre et de l'améliorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=0)\n",
      "[0 1]\n",
      "[0 1]\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]]\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "0.9736842105263158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0), n_iter=5,\n",
      "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000029F7A0141D0>,\n",
      "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000029F7982FF90>},\n",
      "                   random_state=0)\n",
      "{'max_depth': 9, 'n_estimators': 4}\n",
      "0.735363411343253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [\n",
    "\t[1, 2, 3],\n",
    "\t[11, 12, 13]\n",
    "]  # 2 samples, 3 features\n",
    "y = [0, 1]  # classes of each sample\n",
    "print(clf.fit(X, y))\n",
    "print(clf.predict(X))  # predict classes of the training data\n",
    "print(clf.predict([[4, 5, 6], [14, 15, 16]]))  # predict classes of new data\n",
    "\n",
    "X = [\n",
    "\t[0, 15],\n",
    "\t[1, -10] \n",
    "]\n",
    "print(StandardScaler().fit(X).transform(X))  # scale data according to computed scaling values\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "\tStandardScaler(),\n",
    "\tLogisticRegression()\n",
    ")\n",
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# fit the whole pipeline\n",
    "print(pipe.fit(X_train, y_train))\n",
    "# we can now use it like any other estimator\n",
    "print(accuracy_score(pipe.predict(X_test), y_test))\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "result = cross_validate(lr, X, y)  # defaults to 5-fold CV\n",
    "print(result['test_score'])  # r_squared score is high because dataset is easy\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                       'max_depth': randint(5, 10)}\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "print(search.fit(X_train, y_train))\n",
    "print(search.best_params_)\n",
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "print(search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code est un ensemble de démonstrations sur comment utiliser plusieurs fonctions et méthodes fournies par la bibliothèque `scikit-learn` pour la classification, la régression, la mise à l'échelle des données, la validation croisée et la recherche d'hyperparamètres.\n",
    "\n",
    "Voici une explication étape par étape:\n",
    "\n",
    "1. **Initialisation et Classification avec RandomForest**:\n",
    "   - Un classificateur basé sur des forêts aléatoires (RandomForestClassifier) est initialisé.\n",
    "   - Il est ensuite formé sur un petit ensemble de données `X` avec des étiquettes correspondantes `y`.\n",
    "   - Après l'entraînement, le classificateur est utilisé pour prédire les classes des données d'entraînement, ainsi que celles de deux nouveaux échantillons.\n",
    "  \n",
    "2. **Mise à l'échelle des données avec StandardScaler**:\n",
    "   - Un exemple démontre comment mettre à l'échelle des données à l'aide de `StandardScaler` pour que ces données aient une moyenne de 0 et un écart-type de 1.\n",
    "  \n",
    "3. **Pipeline avec StandardScaler et LogisticRegression**:\n",
    "   - Une pipeline est créée, combinant la mise à l'échelle des données et la régression logistique.\n",
    "   - L'ensemble de données Iris est chargé et divisé en ensembles d'entraînement et de test.\n",
    "   - La pipeline est formée sur l'ensemble d'entraînement et évaluée sur l'ensemble de test pour obtenir un score d'exactitude.\n",
    "  \n",
    "4. **Validation croisée avec LinearRegression**:\n",
    "   - Un ensemble de données de régression est généré.\n",
    "   - Une régression linéaire est évaluée à l'aide d'une validation croisée (par défaut 5 plis) pour obtenir des scores R^2 sur les différents plis.\n",
    "  \n",
    "5. **Recherche d'hyperparamètres avec RandomizedSearchCV**:\n",
    "   - L'ensemble de données du logement en Californie est chargé et divisé en ensembles d'entraînement et de test.\n",
    "   - Une recherche aléatoire est effectuée sur un ensemble de forêts aléatoires (RandomForestRegressor) pour trouver la meilleure combinaison d'hyperparamètres `n_estimators` et `max_depth`.\n",
    "   - Une fois la recherche terminée, les meilleurs hyperparamètres sont affichés et le modèle final est évalué sur l'ensemble de test pour obtenir un score R^2.\n",
    "  \n",
    "En résumé, ce code présente différentes façons d'entraîner, de prétraiter et d'évaluer des modèles en utilisant scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Améliorations possibles du code </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code présenté est une démonstration de base des fonctionnalités de `scikit-learn`. Il existe cependant plusieurs améliorations et ajustements que vous pourriez envisager d'apporter pour l'optimisation, la généralisation et la simplification. Voici ce qu'on pourrait améliorer :\n",
    "\n",
    "1. **Séparation des démonstrations**:\n",
    "   - Pour une meilleure organisation et lisibilité, séparer les différentes démonstrations en fonctions ou blocs distincts.\n",
    "\n",
    "2. **Utilisation d'un plus grand ensemble de données**:\n",
    "   - Les démonstrations avec des petits ensembles de données (comme `X = [[1, 2, 3], [11, 12, 13]]`) ne sont pas très significatives. Utiliser un ensemble de données plus large peut aider à mieux démontrer l'utilité et la capacité des modèles.\n",
    "\n",
    "3. **Optimisation de `RandomizedSearchCV`**:\n",
    "   - Augmenter la valeur de `n_iter` pour explorer un plus grand espace d'hyperparamètres.\n",
    "   - Étendre la plage des hyperparamètres (par exemple, recherchez sur un plus grand nombre d'estimateurs ou sur plus de profondeurs).\n",
    "   - Ajouter d'autres hyperparamètres pertinents à la recherche, comme `min_samples_split` ou `max_features`.\n",
    "   - Utiliser `GridSearchCV` pour explorer toutes les combinaisons possibles d'hyperparamètres au lieu d'une sélection aléatoire.\n",
    "\n",
    "4. **Validation croisée**:\n",
    "   - Pour de meilleurs résultats, augmenter le nombre de plis (k) dans la validation croisée ou envisager d'utiliser une StratifiedKFold pour des problèmes de classification pour garantir que chaque pli est un bon représentant de l'ensemble.\n",
    "\n",
    "5. **Evaluation supplémentaire**:\n",
    "   - En plus du score d'exactitude ou R^2, envisager d'afficher d'autres métriques d'évaluation comme la matrice de confusion, le rappel, la précision, le score F1, le ROC AUC, etc.\n",
    "   \n",
    "6. **Visualisation**:\n",
    "   - Intégrer des graphiques pour mieux comprendre les résultats. Par exemple, visualiser l'importance des caractéristiques pour les forêts aléatoires ou tracer des courbes ROC pour la classification.\n",
    "\n",
    "7. **Prétraitement amélioré**:\n",
    "   - Envisager d'utiliser d'autres techniques de prétraitement comme la normalisation MinMax, l'encodage à chaud pour les variables catégorielles ou la réduction de dimensionnalité avec PCA.\n",
    "\n",
    "8. **Gestion des erreurs**:\n",
    "   - Ajouter des blocs try-except pour gérer les erreurs potentielles, comme des problèmes d'ajustement du modèle, des données manquantes, etc.\n",
    "\n",
    "9. **Commentaires et documentation**:\n",
    "   - Ajouter des commentaires détaillés et une documentation pour chaque bloc de code, afin que d'autres personnes puissent facilement comprendre et modifier le code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExécution des démonstrations :\n",
      "\n",
      "\n",
      "\n",
      "\t--- Démonstration RandomForest ---\n",
      "\n",
      "[0 1]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "\t--- Démonstration StandardScaler ---\n",
      "\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]]\n",
      "\n",
      "\n",
      "\t--- Démonstration Pipeline ---\n",
      "\n",
      "0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t--- Démonstration LinearRegression ---\n",
      "\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "\t--- Démonstration RandomizedSearchCV ---\n",
      "\n",
      "{'max_depth': 9, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 17}\n",
      "0.7134662966407328\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ----------------- Fonction pour la démonstration RandomForest -----------------\n",
    "\n",
    "def random_forest_demo():\n",
    "    print(\"\\n\\n\\t--- Démonstration RandomForest ---\\n\")\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    X_demo = [\n",
    "        [1, 2, 3],\n",
    "        [11, 12, 13]\n",
    "    ] \n",
    "    y_demo = [0, 1] \n",
    "    clf.fit(X_demo, y_demo)\n",
    "    \n",
    "    print(clf.predict(X_demo))\n",
    "    print(clf.predict([[4, 5, 6], [14, 15, 16]]))\n",
    "\n",
    "\n",
    "# ------------ Fonction pour la mise à l'échelle avec StandardScaler -------------\n",
    "\n",
    "def standard_scaler_demo():\n",
    "    print(\"\\n\\n\\t--- Démonstration StandardScaler ---\\n\")\n",
    "    X_demo = [\n",
    "        [0, 15],\n",
    "        [1, -10]\n",
    "    ]\n",
    "    print(StandardScaler().fit(X_demo).transform(X_demo))\n",
    "\n",
    "\n",
    "# --------------- Fonction pour la pipeline avec LogisticRegression ---------------\n",
    "\n",
    "def logistic_regression_pipeline():\n",
    "    print(\"\\n\\n\\t--- Démonstration Pipeline ---\\n\")\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression()\n",
    "    )\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(accuracy_score(y_pred, y_test))\n",
    "    \n",
    "    # Affichage des métriques supplémentaires\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(load_iris().target_names))\n",
    "    plt.xticks(tick_marks, load_iris().target_names)\n",
    "    plt.yticks(tick_marks, load_iris().target_names)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --------------- Fonction pour la validation croisée avec LinearRegression ---------------\n",
    "\n",
    "def linear_regression_demo():\n",
    "    print(\"\\n\\n\\t--- Démonstration LinearRegression ---\\n\")\n",
    "    X, y = make_regression(n_samples=1000, random_state=0)\n",
    "    lr = LinearRegression()\n",
    "    result = cross_validate(lr, X, y, cv=10)  # Utilisation d'une 10-fold CV\n",
    "    print(result['test_score'])\n",
    "\n",
    "\n",
    "# --------------- Fonction pour RandomizedSearchCV avec RandomForestRegressor ---------------\n",
    "\n",
    "def randomized_search_demo():\n",
    "    print(\"\\n\\n\\t--- Démonstration RandomizedSearchCV ---\\n\")\n",
    "    \n",
    "    X, y = fetch_california_housing(return_X_y=True)\n",
    "    \n",
    "    # Utiliser un sous-ensemble des données\n",
    "    X, y = X[:2000], y[:2000]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    param_distributions = {\n",
    "        'n_estimators': randint(1, 50),\n",
    "        'max_depth': randint(1, 10),\n",
    "        'min_samples_split': randint(2, 5),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=0),\n",
    "        n_iter=10,\n",
    "        param_distributions=param_distributions,\n",
    "        random_state=0,\n",
    "        cv=10\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(search.best_params_)\n",
    "    print(search.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- Exécution des démonstrations -----------------\n",
    "\n",
    "print(\"\\tExécution des démonstrations :\\n\")\n",
    "random_forest_demo()\n",
    "standard_scaler_demo()\n",
    "logistic_regression_pipeline()\n",
    "linear_regression_demo()\n",
    "randomized_search_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Données Iris </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# fit the whole pipeline\n",
    "print(pipe.fit(X_train, y_train))\n",
    "# we can now use it like any other estimator\n",
    "print(accuracy_score(pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue plusieurs opérations sur l'ensemble de données \"Iris\" en utilisant un pipeline. Voici une explication simple étape par étape :\n",
    "\n",
    "1. **Chargement de l'ensemble de données Iris** : Les données d'Iris sont chargées, où \"`X`\" contient les caractéristiques (les mesures des fleurs) et \"`y`\" contient les étiquettes de classe (les espèces de fleurs).\n",
    "\n",
    "2. **Division des données en ensembles d'entraînement et de test** : Les données sont séparées en deux ensembles, l'un pour l'entraînement (`X_train`, `y_train`) et l'autre pour les tests (`X_test`, `y_test`). Cela permet d'évaluer la performance du modèle sur des données qu'il n'a pas encore vues.\n",
    "\n",
    "2. **Création du pipeline : Un pipeline est créé en combinant deux étapes** : la mise à l'échelle des données avec `StandardScaler()` et l'entraînement d'un modèle de régression logistique avec `LogisticRegression()`.\n",
    "\n",
    "3. **Entraînement du pipeline** : Le pipeline est entraîné sur l'ensemble d'entraînement (`X_train`, `y_train`) en utilisant `pipe.fit(X_train, y_train)`.\n",
    "\n",
    "4. **Prédiction et évaluation** : Le modèle entraîné est utilisé pour faire des prédictions sur l'ensemble de test (`X_test`), puis la précision des prédictions est calculée avec `accuracy_score()`. Cela mesure à quel point les prédictions du modèle sont correctes par rapport aux étiquettes réelles.\n",
    "\n",
    "En résumé, ce code charge les données Iris, les divise en ensembles d'entraînement et de test, puis utilise un pipeline pour mettre à l'échelle les données et entraîner un modèle de régression logistique. Enfin, il évalue la précision du modèle sur les données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Régression linéaire </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "result = cross_validate(lr, X, y)  # defaults to 5-fold CV\n",
    "print(result['test_score'])  # r_squared score is high because dataset is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue des opérations liées à la régression linéaire en utilisant une technique appelée \"validation croisée\". Voici une explication simple étape par étape :\n",
    "\n",
    "1. **Création de données artificielles** : Un ensemble de données est généré avec 1000 échantillons (lignes) et des valeurs aléatoires. Les caractéristiques sont stockées dans \"`X`\", et les valeurs cibles (ce que nous essayons de prédire) sont stockées dans \"`y`\".\n",
    "\n",
    "2. **Création d'un modèle de régression linéaire** : Un modèle de régression linéaire est créé et stocké dans la variable \"`lr`\". Ce modèle sera utilisé pour effectuer des prédictions basées sur les données.\n",
    "\n",
    "3. **Validation croisée** : La fonction `cross_validate()` est utilisée pour évaluer les performances du modèle de régression linéaire. La validation croisée est une technique qui divise les données en plusieurs sous-ensembles, puis entraîne et évalue le modèle plusieurs fois. Dans ce cas, la validation croisée utilise la métrique par défaut (`r_squared`) pour évaluer la performance du modèle.\n",
    "\n",
    "4. **Impression des scores de test** : Les scores de test issus de la validation croisée sont imprimés à l'écran en utilisant `print(result['test_score'])`. Ces scores reflètent à quel point le modèle de régression linéaire est performant pour prédire les valeurs cibles. Le fait que le score R² soit élevé suggère que le modèle s'adapte bien aux données, ce qui signifie qu'il est capable de faire des prédictions précises.\n",
    "\n",
    "En résumé, ce code génère des données, crée un modèle de régression linéaire, utilise la validation croisée pour évaluer sa performance, puis affiche les scores de test pour indiquer à quel point le modèle est bon pour faire des prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> RandomForestRegressor </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0), n_iter=5,\n",
      "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000029F7B13C310>,\n",
      "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000029F7B0C6090>},\n",
      "                   random_state=0)\n",
      "{'max_depth': 9, 'n_estimators': 4}\n",
      "0.735363411343253\n"
     ]
    }
   ],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                       'max_depth': randint(5, 10)}\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "print(search.fit(X_train, y_train))\n",
    "print(search.best_params_)\n",
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "print(search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue une recherche aléatoire de paramètres pour un modèle de régression RandomForestRegressor sur l'ensemble de données \"California Housing\". Voici une explication étape par étape :\n",
    "\n",
    "1. **Chargement et division des données** : Les données \"California Housing\" sont chargées, puis divisées en ensembles d'entraînement (`X_train`, `y_train`) et de test (`X_test`, `y_test`).\n",
    "\n",
    "2. **Définition de l'espace des paramètres** : Un espace de paramètres à explorer est défini dans \"`param_distributions`\". Il s'agit des paramètres possibles pour le modèle de régression aléatoire, tels que le nombre d'arbres dans la forêt (\"`n_estimators`\") et la profondeur maximale des arbres (\"`max_depth`\"). Ces paramètres seront ajustés pour trouver les meilleures valeurs.\n",
    "\n",
    "3. **Création d'un objet de recherche aléatoire** : Un objet `RandomizedSearchCV` est créé. Il utilise le modèle `RandomForestRegressor` comme estimateur de base et effectue une recherche aléatoire dans l'espace des paramètres défini précédemment. La recherche est limitée à 5 itérations (`n_iter=5`) pour des raisons de performance.\n",
    "\n",
    "4. **Ajustement du modèle aux données d'entraînement** : Le modèle de recherche aléatoire est ajusté aux données d'entraînement (`X_train`, `y_train`) en utilisant `search.fit(X_train, y_train)`.\n",
    "\n",
    "5. **Affichage des meilleurs paramètres** : Les meilleurs paramètres trouvés par la recherche aléatoire sont affichés à l'aide de `print(search.best_params_)`. Ces paramètres sont ceux qui donnent la meilleure performance sur les données d'entraînement.\n",
    "\n",
    "6. **Évaluation du modèle** : Enfin, le modèle avec les meilleurs paramètres trouvés est évalué sur les données de test (`X_test`, `y_test`) en utilisant `search.score(X_test, y_test)`. Cette étape mesure à quel point le modèle est bon pour faire des prédictions sur de n`ouvelles données.\n",
    "\n",
    "En résumé, ce code cherche les meilleurs paramètres pour un modèle de régression aléatoire en utilisant une recherche aléatoire sur un ensemble de données \"California Housing\". Il ajuste ensuite le modèle avec les meilleurs paramètres trouvés et évalue sa performance sur les données de test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
